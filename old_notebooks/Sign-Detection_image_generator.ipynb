{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a5ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = str(Path.cwd() / \"src\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from reader import Reader\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import mimetypes\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "from skimage import exposure, transform\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2b15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"../ML-Lab_data/pickle/data_1.pickle\", 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "file = open(r\"../ML-Lab_data/pickle/labels_1.pickle\", 'rb')\n",
    "labels = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f70030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [(next(iter(k))[0], next(iter(k))[1], next(iter(k))[0]+64, next(iter(k))[1]+64) for k in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c5be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data and targets to NumPy arrays, scaling the input\n",
    "# pixel intensities from the range [0, 255] to [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "targets = np.array(targets, dtype=\"float32\")\n",
    "\n",
    "# partition the data into training and testing splits using 90% of\n",
    "# the data for training and the remaining 10% for testing\n",
    "split = train_test_split(data, targets, test_size=0.25, random_state=42)\n",
    "\n",
    "# unpack the data split\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce2031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "#cv2.imshow(\"test\", data[0])\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "shape = data[0].shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d9e56ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG16 network, ensuring the head FC layers are left off\n",
    "vgg = VGG16(weights=\"imagenet\", include_top=False,\n",
    "input_tensor=Input(shape=shape))\n",
    "\n",
    "# freeze all VGG layers so they will *not* be updated during the\n",
    "# training process\n",
    "vgg.trainable = False\n",
    "\n",
    "# flatten the max-pooling output of VGG\n",
    "flatten = vgg.output\n",
    "flatten = Flatten()(flatten)\n",
    "\n",
    "# construct a fully-connected layer header to output the predicted\n",
    "# bounding box coordinates\n",
    "bboxHead = Dense(64, activation=\"relu\")(flatten)\n",
    "bboxHead = Dense(32, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(16, activation=\"relu\")(bboxHead)\n",
    "bboxHead = Dense(4, activation=\"sigmoid\")(bboxHead)\n",
    "\n",
    "# construct the model we will fine-tune for bounding box regression\n",
    "model = Model(inputs=vgg.input, outputs=bboxHead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5ea632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our initial learning rate, number of epochs to train\n",
    "# for, and the batch size\n",
    "INIT_LR = 1e-3#4\n",
    "NUM_EPOCHS = 25\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8996463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 192, 320, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 320, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 160, 64)       0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 160, 128)      73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 160, 128)      147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 80, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 80, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 24, 40, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 24, 40, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 24, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 24, 40, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 12, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 12, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 12, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 12, 20, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 10, 512)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30720)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1966144   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 16,683,508\n",
      "Trainable params: 1,968,820\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holz_so\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer, compile the model, and show the model\n",
    "# summary\n",
    "opt = Adam(lr=INIT_LR)\n",
    "model.compile(loss=\"mae\", optimizer=opt)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9a241a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training bounding box regressor...\n",
      "235/235 [==============================] - 1893s 8s/step - loss: 132.8443 - val_loss: 131.1390\n"
     ]
    }
   ],
   "source": [
    "# train the network for bounding box regression\n",
    "print(\"[INFO] training bounding box regressor...\")\n",
    "H = model.fit(\n",
    "    trainImages, trainTargets,\n",
    "    validation_data=(testImages, testTargets),\n",
    "    #batch_size=BATCH_SIZE,\n",
    "    epochs=1,#NUM_EPOCHS,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e82ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for image, bounding in zip(data, targets):\n",
    "    print(image.shape)\n",
    "    preds = model.predict(image)\n",
    "    print(preds)\n",
    "    (startX, startY, endX, endY) = preds[0]\n",
    "    \n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # scale the predicted bounding box coordinates based on the image\n",
    "    # dimensions\n",
    "    startX = int(startX * w)\n",
    "    startY = int(startY * h)\n",
    "    endX = int(endX * w)\n",
    "    endY = int(endY * h)\n",
    "\n",
    "    # draw the predicted bounding box on the image\n",
    "    cv2.rectangle(image, (startX, startY), (endX, endY), (0, 255, 0), 1)\n",
    "    cv2.rectangle(image, (bounding[0], bounding[1]), (bounding[2], bounding[3]), (0, 0, 255), 1)\n",
    "\n",
    "    # show the output image\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbf64ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
