{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06356a0a-1484-4036-96f1-4ba4515c9a9a",
   "metadata": {},
   "source": [
    "# Modelltraining Schilder Klassifizierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c382d4a-290f-489d-8aa6-72c2f36fa2c8",
   "metadata": {},
   "source": [
    "## Bearbeiter\n",
    "**TINF19-IT2**  \n",
    "Patrick Küsters (9815596)  \n",
    "Nick Kramer (3122448)  \n",
    "**TINF19-IT1**  \n",
    "Sören Holzenkamp (8528927)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7160c-2122-4147-9f1e-5544b4457c80",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Lokal entwickelte Skripte und Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3eccff-140d-464d-98b8-3068a43a6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = str(Path.cwd() / \"src\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from reader import Reader\n",
    "from display_data import ImageDisplayer\n",
    "from image_detection import predict_and_display_img\n",
    "from evaluation import plot_confusion_matrix\n",
    "import collage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1974a-756f-4069-b5d8-397df462cb08",
   "metadata": {},
   "source": [
    "Externe Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a67296-cb4c-4300-83cc-711d9ef801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import AvgPool2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import exposure, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mimetypes\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39772256-fd84-4678-ac98-2b48c2e86152",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"./pickle/data_3.pickle\", 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "file = open(r\"./pickle/labels_3.pickle\", 'rb')\n",
    "labels = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cffdb774-6146-4083-b7c6-1efb7ba6b7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830d57f5-710f-4471-a4a1-11882471ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "input_shape = data[0].shape\n",
    "for k in labels:\n",
    "    a = list(k.keys())\n",
    "    a.sort(key=lambda x: (x[0], x[1])) ## wichtig! Erläuterung: nächste Zelle\n",
    "    temp = [] #input vektor for model\n",
    "    for e in a:\n",
    "        x1, y1, x2, y2 = e #extract coordinates\n",
    "        h, w = input_shape[:2]\n",
    "        temp.append(x1/w) #scale with image shape\n",
    "        temp.append(y1/h)\n",
    "        temp.append(x2/w)\n",
    "        temp.append(y2/h)\n",
    "    targets.append(temp)\n",
    "    \n",
    "# convert the data and targets to NumPy arrays, scaling the input\n",
    "# pixel intensities from the range [0, 255] to [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "targets = np.array(targets, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753648e5-2342-405f-b89f-f16ad3024685",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(data, targets, test_size=0.25, random_state=42)\n",
    "\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "\n",
    "split = train_test_split(testImages, testTargets, test_size=0.5, random_state=42)\n",
    "\n",
    "(validationImages, testImages) = split[:2]\n",
    "(validationTargets, testTargets) = split[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccbdc2e9-701d-4b9b-a597-fc90294f9523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 400, 680, 3)]     0         \n",
      "                                                                 \n",
      " bl_2 (Conv2D)               (None, 400, 680, 16)      448       \n",
      "                                                                 \n",
      " bl_3 (MaxPooling2D)         (None, 200, 340, 16)      0         \n",
      "                                                                 \n",
      " bl_4 (Conv2D)               (None, 200, 340, 32)      4640      \n",
      "                                                                 \n",
      " bl_5 (MaxPooling2D)         (None, 100, 170, 32)      0         \n",
      "                                                                 \n",
      " bl_6 (Conv2D)               (None, 100, 170, 64)      18496     \n",
      "                                                                 \n",
      " bl_7 (MaxPooling2D)         (None, 50, 85, 64)        0         \n",
      "                                                                 \n",
      " bl_8 (Flatten)              (None, 272000)            0         \n",
      "                                                                 \n",
      " bb_1 (Dense)                (None, 128)               34816128  \n",
      "                                                                 \n",
      " bb_2 (Dense)                (None, 64)                8256      \n",
      "                                                                 \n",
      " bb_3 (Dense)                (None, 32)                2080      \n",
      "                                                                 \n",
      " bb_head (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,850,180\n",
      "Trainable params: 34,850,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(input_shape)\n",
    "\n",
    "#create the base layers\n",
    "base_layers = Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(input_layer)\n",
    "base_layers = MaxPooling2D(name='bl_3')(base_layers)\n",
    "base_layers = Conv2D(32, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_5')(base_layers)\n",
    "base_layers = Conv2D(64, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_7')(base_layers)\n",
    "base_layers = Flatten(name='bl_8')(base_layers)\n",
    "\n",
    "#create the localiser branch\n",
    "locator_branch = Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "locator_branch = Dense(64, activation='relu', name='bb_2')(locator_branch)\n",
    "locator_branch = Dense(32, activation='relu', name='bb_3')(locator_branch)\n",
    "locator_branch = Dense(4, activation='sigmoid', name='bb_head')(locator_branch)\n",
    "\n",
    "model = tf.keras.Model(input_layer, outputs=locator_branch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "561e3ac8-b201-4d50-84bf-cd793ef54732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss = tf.keras.losses.MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3af647a-c520-4f1e-b7dd-b4dea8a2a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as kb\n",
    "def custom_loss(y_actual,y_pred):\n",
    "    print(y_actual.shape)\n",
    "    print(y_actual[0].shape)\n",
    "    print(y_actual[0][0].shape)\n",
    "    wu = y_actual[2] - y_actual[0]\n",
    "    hu = y_actual[1] - y_actual[0]\n",
    "    wv = y_pred[2] - y_pred[0]\n",
    "    hv = y_pred[1] - y_pred[0]\n",
    "    xu = y_actual[0]\n",
    "    yu = y_actual[1]\n",
    "    xv = y_pred[0]\n",
    "    yv = y_pred[1]\n",
    "    au = wu*hu\n",
    "    av = wv*hv\n",
    "    iw = kb.min(xu+0.5*wu, xv+0.5*wv)-kb.max(xu-0.5*wu, xv-0.5*wv)\n",
    "    ih = kb.min(yu+0.5*hu, yv+0.5*hv)-kb.max(yu-0.5*hu, yv-0.5*hv)\n",
    "    iq = kb.max(iw, 0)\n",
    "    ih = kb.max(ih, 0)\n",
    "    i = iw*ih\n",
    "    u = au+av-i\n",
    "    iou = i/u\n",
    "    l = kb.log(iou+0.0001)\n",
    "    return l\n",
    "loss = custom_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfad960d-3b15-4f5a-8923-cf6fa24c65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cb65a3c-4a76-4f10-a3cb-8eed88dbc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ad96439-a467-44c3-8af7-69b0913b5792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 01:53:14.745160: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 24480000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "(10, 4)\n",
      "(4,)\n",
      "()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/soeren/anaconda3/envs/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_9412/3945805092.py\", line 16, in custom_loss  *\n        iw = kb.min(xu+0.5*wu, xv+0.5*wv)-kb.max(xu-0.5*wu, xv-0.5*wv)\n    File \"/home/soeren/anaconda3/envs/ml/lib/python3.10/site-packages/keras/backend.py\", line 2435, in min\n        return tf.reduce_min(x, axis, keepdims)\n\n    TypeError: Value passed to parameter 'reduction_indices' has DataType float32 not in list of allowed values: int32, int64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainTargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtestImages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestTargets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m             \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m             \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/soeren/anaconda3/envs/ml/lib/python3.10/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_9412/3945805092.py\", line 16, in custom_loss  *\n        iw = kb.min(xu+0.5*wu, xv+0.5*wv)-kb.max(xu-0.5*wu, xv-0.5*wv)\n    File \"/home/soeren/anaconda3/envs/ml/lib/python3.10/site-packages/keras/backend.py\", line 2435, in min\n        return tf.reduce_min(x, axis, keepdims)\n\n    TypeError: Value passed to parameter 'reduction_indices' has DataType float32 not in list of allowed values: int32, int64\n"
     ]
    }
   ],
   "source": [
    "training = model.fit(trainImages, trainTargets,\n",
    "             validation_data=(testImages, testTargets),\n",
    "             batch_size=10,\n",
    "             epochs=epoch_num,\n",
    "             shuffle=True,\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a3d21-3977-40c6-883e-d1d2ba9408f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(r\"./models/models_regr_3signs_1\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba8f55-fcb5-44f1-9c2f-b11fce48f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epoch_num), training.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epoch_num), training.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "#plt.show()\n",
    "plt.savefig('./images/training3_15_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b17c3-77c7-442e-b44e-1c40d1fb89ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
