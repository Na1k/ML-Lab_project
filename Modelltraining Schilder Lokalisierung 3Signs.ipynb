{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06356a0a-1484-4036-96f1-4ba4515c9a9a",
   "metadata": {},
   "source": [
    "# Modelltraining Lokalisierung von 3 Verkehrsschildern pro Bild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c382d4a-290f-489d-8aa6-72c2f36fa2c8",
   "metadata": {},
   "source": [
    "## Bearbeiter\n",
    "**TINF19-IT2**  \n",
    "Patrick Küsters (9815596)  \n",
    "Nick Kramer (3122448)  \n",
    "**TINF19-IT1**  \n",
    "Sören Holzenkamp (8528927)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7160c-2122-4147-9f1e-5544b4457c80",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Lokal entwickelte Skripte und Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3eccff-140d-464d-98b8-3068a43a6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "module_path = str(Path.cwd() / \"src\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from reader import Reader\n",
    "from display_data import ImageDisplayer\n",
    "from image_detection import predict_and_display_img\n",
    "from evaluation import plot_confusion_matrix\n",
    "import collage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d1974a-756f-4069-b5d8-397df462cb08",
   "metadata": {},
   "source": [
    "Externe Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44a67296-cb4c-4300-83cc-711d9ef801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import AvgPool2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from skimage import exposure, transform\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mimetypes\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39772256-fd84-4678-ac98-2b48c2e86152",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"./pickle/data_3.pickle\", 'rb')\n",
    "data = pickle.load(file)\n",
    "file.close()\n",
    "file = open(r\"./pickle/labels_3.pickle\", 'rb')\n",
    "labels = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830d57f5-710f-4471-a4a1-11882471ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "input_shape = data[0].shape\n",
    "for k in labels:\n",
    "    a = list(k.keys())\n",
    "    a.sort(key=lambda x: (x[0], x[1])) # !!!\n",
    "    temp = [] #input vektor for model\n",
    "    for e in a:\n",
    "        x1, y1, x2, y2 = e #extract coordinates\n",
    "        h, w = input_shape[:2]\n",
    "        temp.append(x1/w) #scale with image shape\n",
    "        temp.append(y1/h)\n",
    "        temp.append(x2/w)\n",
    "        temp.append(y2/h)\n",
    "    targets.append(temp)\n",
    "    \n",
    "# convert the data and targets to NumPy arrays, scaling the input\n",
    "# pixel intensities from the range [0, 255] to [0, 1]\n",
    "data = np.array(data, dtype=\"float32\") / 255.0\n",
    "targets = np.array(targets, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "753648e5-2342-405f-b89f-f16ad3024685",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(data, targets, test_size=0.25, random_state=42)\n",
    "\n",
    "(trainImages, testImages) = split[:2]\n",
    "(trainTargets, testTargets) = split[2:4]\n",
    "\n",
    "split = train_test_split(testImages, testTargets, test_size=0.5, random_state=42)\n",
    "\n",
    "(validationImages, testImages) = split[:2]\n",
    "(validationTargets, testTargets) = split[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccbdc2e9-701d-4b9b-a597-fc90294f9523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 192, 3)]     0         \n",
      "                                                                 \n",
      " bl_2 (Conv2D)               (None, 128, 192, 16)      448       \n",
      "                                                                 \n",
      " bl_3 (MaxPooling2D)         (None, 64, 96, 16)        0         \n",
      "                                                                 \n",
      " bl_4 (Conv2D)               (None, 64, 96, 24)        3480      \n",
      "                                                                 \n",
      " bl_5 (MaxPooling2D)         (None, 32, 48, 24)        0         \n",
      "                                                                 \n",
      " bl_6 (Conv2D)               (None, 32, 48, 32)        6944      \n",
      "                                                                 \n",
      " bl_7 (MaxPooling2D)         (None, 16, 24, 32)        0         \n",
      "                                                                 \n",
      " bl_8 (Conv2D)               (None, 16, 24, 48)        13872     \n",
      "                                                                 \n",
      " bl_9 (MaxPooling2D)         (None, 8, 12, 48)         0         \n",
      "                                                                 \n",
      " bl_10 (Conv2D)              (None, 8, 12, 64)         27712     \n",
      "                                                                 \n",
      " bl_11 (MaxPooling2D)        (None, 4, 6, 64)          0         \n",
      "                                                                 \n",
      " bl_12 (Conv2D)              (None, 4, 6, 96)          55392     \n",
      "                                                                 \n",
      " bl_13 (MaxPooling2D)        (None, 2, 3, 96)          0         \n",
      "                                                                 \n",
      " bl_14 (Conv2D)              (None, 2, 3, 128)         110720    \n",
      "                                                                 \n",
      " bl_15 (MaxPooling2D)        (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " bl_18 (Flatten)             (None, 128)               0         \n",
      "                                                                 \n",
      " bb_1 (Dense)                (None, 128)               16512     \n",
      "                                                                 \n",
      " bb_2 (Dense)                (None, 96)                12384     \n",
      "                                                                 \n",
      " bb_3 (Dense)                (None, 64)                6208      \n",
      "                                                                 \n",
      " bb_4 (Dense)                (None, 48)                3120      \n",
      "                                                                 \n",
      " bb_5 (Dense)                (None, 32)                1568      \n",
      "                                                                 \n",
      " bb_6 (Dense)                (None, 16)                528       \n",
      "                                                                 \n",
      " bb_head (Dense)             (None, 12)                204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 259,092\n",
      "Trainable params: 259,092\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 03:43:53.527613: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(input_shape)\n",
    "\n",
    "#create the base layers\n",
    "base_layers = Conv2D(16, 3, padding='same', activation='relu', name='bl_2')(input_layer)\n",
    "base_layers = MaxPooling2D(name='bl_3')(base_layers)\n",
    "base_layers = Conv2D(24, 3, padding='same', activation='relu', name='bl_4')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_5')(base_layers)\n",
    "base_layers = Conv2D(32, 3, padding='same', activation='relu', name='bl_6')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_7')(base_layers)\n",
    "base_layers = Conv2D(48, 3, padding='same', activation='relu', name='bl_8')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_9')(base_layers)\n",
    "base_layers = Conv2D(64, 3, padding='same', activation='relu', name='bl_10')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_11')(base_layers)\n",
    "base_layers = Conv2D(96, 3, padding='same', activation='relu', name='bl_12')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_13')(base_layers)\n",
    "base_layers = Conv2D(128, 3, padding='same', activation='relu', name='bl_14')(base_layers)\n",
    "base_layers = MaxPooling2D(name='bl_15')(base_layers)\n",
    "base_layers = Flatten(name='bl_18')(base_layers)\n",
    "\n",
    "#create the localiser branch\n",
    "locator_branch = Dense(128, activation='relu', name='bb_1')(base_layers)\n",
    "locator_branch = Dense(96, activation='relu', name='bb_2')(locator_branch)\n",
    "locator_branch = Dense(64, activation='relu', name='bb_3')(locator_branch)\n",
    "locator_branch = Dense(48, activation='relu', name='bb_4')(locator_branch)\n",
    "locator_branch = Dense(32, activation='relu', name='bb_5')(locator_branch)\n",
    "locator_branch = Dense(16, activation='relu', name='bb_6')(locator_branch)\n",
    "locator_branch = Dense(12, activation='sigmoid', name='bb_head')(locator_branch)\n",
    "\n",
    "model = tf.keras.Model(input_layer, outputs=locator_branch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561e3ac8-b201-4d50-84bf-cd793ef54732",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfad960d-3b15-4f5a-8923-cf6fa24c65ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb65a3c-4a76-4f10-a3cb-8eed88dbc4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad96439-a467-44c3-8af7-69b0913b5792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 03:43:53.710587: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 4423680000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - ETA: 0s - loss: 0.1530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 03:49:06.013573: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 737280000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 317s 211ms/step - loss: 0.1530 - val_loss: 0.0982\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 206s 137ms/step - loss: 0.0736 - val_loss: 0.0598\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 221s 147ms/step - loss: 0.0517 - val_loss: 0.0489\n",
      "Epoch 4/20\n",
      " 695/1500 [============>.................] - ETA: 1:36 - loss: 0.0459"
     ]
    }
   ],
   "source": [
    "training = model.fit(trainImages, trainTargets,\n",
    "             validation_data=(testImages, testTargets),\n",
    "             batch_size=10,\n",
    "             epochs=epoch_num,\n",
    "             shuffle=True,\n",
    "             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a3d21-3977-40c6-883e-d1d2ba9408f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"./models/regr_3signs_2.pickle\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edba8f55-fcb5-44f1-9c2f-b11fce48f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, epoch_num), training.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, epoch_num), training.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Bounding Box Regression Loss on Training Set\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "#plt.show()\n",
    "plt.savefig('./images/training3_20_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b17c3-77c7-442e-b44e-1c40d1fb89ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
